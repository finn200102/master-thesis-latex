\chapter{Vorhersage von Entladungscharakteristika}
\label{chap:prediction}

\section{Zielsetzung und Hypothesen}

\subsection{Motivation und Problemstellung}
Die frühzeitige Vorhersage von Entladungscharakteristika in Gasentladungen ist von fundamentaler Bedeutung für die Entwicklung von Schutzsystemen und das Verständis der zugrundeliegenden physikalischen Prozesse. Vorläufersignaturen die vor dem eigentlichen Entladungsevent auftreten, enthalten potentiell Infromationen über die nachfolgende Entladung. Entschieden wurde sich für eine automatische Extraktion relevanter Merkmale aus den hochdimensionalen Zeitreihendaten der Vorläuferströme und der nachfolgenden Identifikation von relevanten Featuren. Dieser Ansatz hat den Vorteil gegenüber einer manuellen Definition von Featuren, dass die Gefahr relevante Muster zu übersehen reduziert wird.
\subsection{Zielsetzung}
Die Ziele für diese Untersuchung sind die Vorhersage kritischer Entladungsparameter, dem Vorläuferabstand \(t_{prec}\) und der Eventlänge \(t_{event}\). Dies soll zur Identifikation physikalisch interpretierbarer Prädikatoren führen, also den wichtigsten Featuren für die verwendeten Zielvariablen und der Vergleich von verschiedenen ML-Algorithmen zur Identifikation des optimalen Modells.
\subsection{Forschungshypothesen}
Die folgenden Hypothesen wurden basierend auf der physikalischen Theorie von Gasentladungen aufgestellt:

\textbf{H1: Prädiktivität der Vorläufersignaturen}\newline
Die Charakteristika der Vorläufersignatur korrelieren signifikant mit dem zeitlichen Abstand zum Hauptevent.\newline
Die Vorläuferphase repräsentiert die Entlwicklung eine leitfähigen Kanals. Die Dynamik dieser Charakteristika sollte messbar sein.\newline

\textbf{H2: Frequenzabhängigkeit}\newline
Hochfrequenze Oszillationen im Megahertzbereich im Vorläuferstrom sind die stärksten Prädiktoren für den Vorläuferabstand.\newline
Auftretende Resonanzphänomene im sich entwickelnden Plasmakanal, die Dynamik diesr sollte mit dem Zustand dieses Kanal korrelieren.\newline

\textbf{H3: Nichtlinearität der Zusammenhänge}\newline
Nichtlienare Modelle (Random Forest, SVR) zeigen signifikant bessere Vorhersageperformance als lineare Modelle.\newline
Die Plasmaphysik von Gasentladungen wird durch nicht lineare Prozesse dominiert (Avalanche-Effekte, Raumladungseffekte).\newline

\textbf{H4: Feature-Redundanz}\newline
Aus der großen Anzahl an initial extrahierten Featuren genügen die Top-n informativsten Features für eine optimale Vorhersageperformance.\newline
Die initial extrahierten Feature sind hochgradig korreliert, eine Reduktion sollte Overfitting vermeiden ohne Infromationsverlust.

\textbf{H5: Einfluss des Spaltabstands}\newline
Größere Spaltabstände führen zu längeren und besser vorhersagbaren Vorläuferabständen.\newline
Größere Spaltabstände erfondern längere Lawinenprozesse und die Bildung von Streamer-Prozessen ist höher, dies führt zu besseren Vorläufersignaturen.

\subsection{Methodischer Ansatz}
Diese Hypothesen werden mit den folgenden systematischen Ansätzen verfolgt. Die automatische Feature-Extraktion erfolgt über die ts-fresh python Bibliothek, hierbei werden \(> 1000\) standardisierte Zeitreihenfeatures extrahiert, somit sind Zeit und Frequenzfeatures gegeben. Die Selektion der Features erfolgt Datengetrieben auf einer univarianten Selektion basierend auf F-Statistik. Es werden systemsatisch lineare und nichtlineare Regressoren verglichen. Es erfolgt eine Hyperparameter-Optimierung via Grid Search. Es folgt eine physikalische Interpretation der Feature-Importance.

\section{Datengrundlage und Vorverarbeitung}
\subsection{Übersicht der Datensätze}
Aus den aufgezeichneten Gasentladungen wurden verschiedene Datensätze gebildet, dabei bei waren die beiden Metriken Vorläuferstart und Vorläuferende relevant.

\begin{table}[h!]
\centering
\caption{Übersicht der verwendeten Datensätze}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c c}
\toprule
\textbf{Datensatz} & \textbf{Segmentierung} & \textbf{Zeitintervall} & \textbf{n} & \textbf{n} & \textbf{Vorläuferabstand} & \textbf{Eventlänge} \\
\midrule
DS1 & automatisch & Vorläuferstart-Ende & \~150 & x & x \\ 
DS2 & manuell & Vorläuferstart-Ende & \~250 & x & x \\
DS3 & automatisch & \SIrange{2e-9}{3e-8}{\second} & & & x \\ 
DS4 & automatisch & \SIrange{3e-8}{1e-5}{\second} & & & x \\
DS5 & automatisch & \SI{1}{\micro\second} & & & x \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection{Datensatz-Spezifikationen}

\textbf{DS1: Automatische segmentierte Vorläufer mit Vorläuferende}\newline
Für diesen Datensatz wurden alle Entladungen selektiert, für die die automatisch gesetzten Vorläuferstart und Vorläuferendewerte eine Differenz größer als \SI{100}{\nano\second} beträgt. Also die Länge der Vorläufersignatur länger als \SI{100}{\nano\second} ist. Es wurden so 192 Entladungen selektiert.

\textbf{DS2: Manuell segmentierte Streamer}\newline
Für diesen Datensatz wurden die Entladungen händisch selektiert, für die ein klares Vorläuferende vorliegen und die eine Streamer ähnlichen Verlauf aufweisen. Es wurden so 250 Werte selektiert.

\textbf{DS3: Automatische segmentierte Vorläufer im Interval \SIrange{2e-9}{3e-8}{\second}}

\textbf{DS4: Automatische segmentierte Vorläufer im Interval \SIrange{3e-8}{1e-5}{\second}}

\textbf{DS5: Automatische segmentierte Features \SI{1}{\micro\second} vor dem Eventstart}


\subsection{Feature-Extraktion mittels tsfresh}
Die Python-Bibliothek tsfresh (Time Series Feature extraction based on Scalable Hypothesis Tests) berechnet automatisch Hunderte von Merkmalen (Features) aus Zeitreihen. Es werden einfache Kennzahlen wie der Mittelwert, Varianz oder Schiefe, aber auch komplexere Maße wie Autokorrelation und Fourier-Koeffizienten berechnet. Die Bibliothek bietet auch Verfahren zur Auswahl relevanter Merkmale mittels statischer Hypothesentests an. Diese Bibliothek eignet sich für große Datensätze.


\subsection{Datenvorverarbeitung}

\textbf{Behandlung fehlender Werte}\newline
Nach der Extraktion der Features für einen Datensatz werden diese auf NaN-Werte untersucht, es wenn ein Feature mit NaN gefunden wurden, wird dieses Feature für alle Entladungen entfernt.

\textbf{Normalisierung}\newline
Es werden alle Features auf \(\mu = 0, \sigma = 1\) standardisiert. Dies führt zu einer gleichen Skala für alle Features, viele Algorithmen sind sensitiv gegenüber den Größenordnungen der Eingabevariablen. Dies ermöglicht ebenfalls ein höhere numerische stabilität.
% Python code ?

\subsection{Feature-Selektrion}

Die initiale Menge an Features von \(> 1000\) wurde systematisch reduziert, durch die Verwendung der univariaten Selektion. Es wurde die scikit-learn Python-Bibliothek verwendet um dessen SelectKBest Funktion zu verwenden. Es werden verschiedene Training-Runs durchgeführt für verschiedene k.% Python code?

\subsection{Train-Test-Aufteilung}
Die Modellvaliderung erfolgt über ein Test-Train Split von 20\% Test-Daten und 80\% Train-Daten. Für kleine Datenmengen gehen so jedoch viele nützliche Trainings-Daten verloheren, die Kreuzvalidierung ermöglicht dies zu kompensieren.


\section{Ergebnisse der Vorläuferabstand-Vorhersage}

\subsection{Charakterisierung der Vorläufersignaturen}
In \figref{fig:comparison_precursor_streamer} sind für DS1 und DS2, also die beiden Datensätze die sich zur Vorhersage des Vorläuferabstandes eignen, die Ströme aus denen die Features extrahiert wurden dargestellt. In \figref{fig:precursor_current_sliece} sind drei Beispiele des Vorläuferstroms zwischen Vorläuferstart und Vorläuferende dargestellt. Es ist zu erkennen, dass alle Vorläufer unter diesen Bedingungen einen ähnlichen periodischen gedämpften Verlauf besitzen die ist ähnlich zu einem wie in \secref{sec:critpoint} erwarten Warnsignal vor einem Übergang des Systems.  Es lässt sich eine Periode von ca. \SI{10}{\nano\second} erkennen und damit eine Frequenz von \SI{100}{\mega\hertz}.

Neben den automatisch bestimmten Grenzen wurden für die längeren Entladungen auch händische Grenzen für den Vorläuferstart und das Vorläuferende gesetzt. In \figref{fig:streamer_current_sliece} sind die Vorläufersignaturen die händisch makiert wurden dargestellt. Ein Vergleich mit \figref{fig:precursor_current_sliece} zeigt einen ähnlichen Verlauf, was zu erwarten war, da die gleiche Strategie verfolgt wurde. Die einzelnen Amplituden unterscheiden sich in dieser Stichprobe untereinander, jedoch ist dies nur eine kleine Stichprobe. Die Periode der einzelnen Ströme liegt ebenfalls im \SI{100}{\mega\hertz} Bereich, wobei neben dieser feinen Struktur noch gröbere auftreten von ca. \SI{10}{\mega\hertz}.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_prec_ts_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:precursor_current_sliece}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_streamer_hand_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:streamer_current_sliece}
    \end{subfigure}
    \caption{Vergleich der Verläufe der Vorläufersignatur}
    \label{fig:comparison_precursor_streamer}
\end{figure}

\subsection{Datensatz DS1: Automatische Segmentierung}

\subsubsection{Verteilung der Zielvariable}
Aufgrund des großen Abstandes dieser Vorläufer, eignet sich dieser zum Test der These, dass der Strom vor der Entladung mit dem Start der Entladung korreliert und ob sich eine solche Vorläufersignatur eignet um den Abstand zum Event vorherzusagen. In \figref{fig:prec_ts_prec_distance_box} stellt die Verteilung der Vorläuferabstände über die Spaltabstände dar. Die Mittelwerte der Vorläuferabstände für all bis auf die \SI{20}{\milli\meter} liegen verteilt um die \SI{1}{\micro\second} mit einigen Ausreißern für die \SI{10}{\milli\meter} und die \SI{11}{\milli\meter}. Für die \SI{20}{\milli\meter} liegen die meißten längeren Vorläuferabstände vor und zugleich liegt auch der Mittelwert für diese weit oben. Dies deutet darauf hin, dass es ab dem Wert die Wahrscheinlichkeit für die Bildung solch langer Vorläuferabstände signifikant ansteigt.


\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_prec_ts_precursor_distance_box.pdf}
      \caption{Verteilung des Vorläuferabstandes}
      \label{fig:prec_ts_prec_distance_box}
\end{figure}

\subsubsection{Modellperformance}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Vorläuferabstände}
\label{tab:prec_distance}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
LinearRegression & Vorläuferabstand & -0,06 & $1{,}75 \times 10^{-12}$ & $1{,}32 \times 10^{-6}$ & $1{,}04 \times 10^{-6}$ \\
RandomForestRegressor & Vorläuferabstand & -0,17 & $1{,}94 \times 10^{-12}$ & $1{,}39 \times 10^{-6}$ & $0{,}35 \times 10^{-7}$ \\

\bottomrule
\end{tabular}%
}
\end{table}

\subsubsection{Analyse}
\label{sec:ds1ana}
In \tabref{tab:prec_distance} sind die gefitteten Modelle für den DS1 Datensatz dargestellt. Das beste Modell ist die LinearRegression mit \(R^2 = -0,06\), jedoch bedeuten ein \(R^2 < 0\), dass das Modell schlechter performt als der Mittelwert des Datensatzes. Dies zeigt, dass sowohl das lineare also auch das nicht lineare Modell nicht den Datensatz wiedergeben können. Die Betrachtung des MAE als alternativen Qualitätsmaß zeigt für den RandomForestRegressor einen deutlich kleineren Wert als für die nach dem \(R^2\) Maß besserem linearen Modell. Hierbei ist zu beachten das der \(R^2\) auch wie der MSE sensitiv auf Ausreißer ist und somit der Anteil an Ausreißern in diesem Datensatz DS1, der kleiner als der DS2 Datensatz ist, groß ist. Die Betrachtung von \figref{fig:prec_ts_prec_distance_box} zeigt, dass das Plottingverfahren des Boxplots 18 Entladungen als Ausreißer makiert hat, dass sind 9,3\% des Datensatzes, somit könnten diese Verantwortlich für die schlechte Performance des Modells sein. Der Vergleich mit dem größeren Datensatz DS2 für diese Zielvariable ist nun von Intresse.

\subsection{Datensatz DS2: Manuelle Streamer-Segmentierung}

\subsubsection{Verteilung der Zielvariable}

In \figref{fig:streamer_hand_prec_distance_box} ist die Verteilung der Vorläuferabstände für die händische Setzung dargestellt. Die Verteilung der Abstände unterscheidet sich zu den automatisch gesetzten Grenzen nicht sonderlich, es ist nur zuerkennen, das für einen kleineren Anteil die Grenzen gesetz wurden. Die Werte liegen ebenfalls im Interval \SIrange{0}{8}{\micro\second}. 
\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_streamer_hand_precursor_distance_box.pdf}
      \caption{Verteilung des Vorläuferabstandes}
      \label{fig:streamer_hand_prec_distance_box}
\end{figure}

\subsubsection{Modellperformance}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Vorläuferabstände}
\label{tab:streamer_prec_distance}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
Random Forest & Vorläuferabstand & 0,55 & $6{,}63 \times 10^{-12}$ & $2{,}57 \times 10^{-6}$ & $1{,}60 \times 10^{-6}$ \\
SVR & Vorläuferabstand & 0,40 & $8{,}91 \times 10^{-12}$ &  \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsubsection{Analyse}
In \tabref{tab:streamer_prec_distance} sind die verschiedenen gefitteten Modelle dargestellt. Das am besten performente Model mit einem \(R^2 = 0.55\) ist der Random Forest, die genaue Wahl an Parametern wurde mit einem Gridsearch optimiert. Es ist an diesem Wert direkt erkenntlich, dass das Model Teile des Systems wiederspiegelt, jedoch nur etwa 55\% der Varianz der Zielvariable. Das Modell hat einen MAE von \SI{1,6}{\micro\second}, somit lässt sich aus der oberen Angabe des Intervalls des Vorläuferabstandes schließen, dass Zielvariable nur begrenzt gut aus den Featuren des Stroms \figref{fig:streamer_current_sliece} bestimmt werden kann. Insbensondere ist zu beachten, dass mehrheitlich kleinere Vorläuferabstände vorliegen, \figref{fig:histogram-precdistance} zeigt diesen linear fallenden Trend. Der MSE mit einem Wert von \SI{2,57}{\micro\second} ist etwas größer da diese Metrik Ausreißer stärker bestraft, der Blick auf \figref{fig:streamer_hand_prec_distance_box} zeigt, dass für einen Spaltabstand von \SI{2}{\centi\meter} der Mittelwert dieser Messungen deutlich über den anderen liegt, zudem sind die Vorläuferabstände für die anderen Spaltabstände um den Mittelwert über ein größeres Intervall verteilt, somit vergrößern diese Ausreißer diese Fehlermetrik etwas.
.

\subsection{Vergleichende Analyse}
Der Vergleich der beiden Datensätze DS1 und DS2 für die Zielvariable des Vorläuferabstandes zeigt eine deutlich unterschiedliche Performance der Modelle. Für den DS1 Datensatz kann kein Modell nach dem \(R^2\) Wert die Zielvariable besser als die einfache Mittelwertbildung vorhersagen. Für den DS2 Datensatz, kann nach dieser Metrik jedoch für das beste Modell ca. 55\% der Varianz der Verteilung dieser Zielvariable erklären. Die Betrachtung anderer Metriken führt jedoch zu einem anderen Schluss, der MAE der nicht auf Ausreißer sensitiv ist für das nicht lineare Modell mit einem Wert von \(0{,}35 \times 10^{-7}\) kleiner als der kleinste MAE des DS2 Datensatzes mit \(1{,}60 \times 10^{-6}\). Dabei ist zu beachten, dass sich die Verteilung der Vorläuferabstände zwischen diesen beiden Datensätzen darin unterscheidet, dass für den DS1 Datensatz viele kurze Abstände auftreten und wenig lange, die für diesen dann oft als Ausreißer behandelt werden. Somit ist der kleinere MAE teilweise dem geschuldet, jedoch wie in \secref{sec:ds1ana} schon diskutiert, ist ein weiterer Aspekt das Verhältnis an Ausreißern die eine Größenordnungen größer als die anderen kleinern Vorläuferabstände sind. Die manuelle Wahl der Grenzen ermöglicht für den DS2, dass längere Vorläuferabstände, die durch die automatische Setzung der Grenzen nicht erkannt wurden, vermehrt auftreten und kleinere Abstände zusätzlich wegen der Fokussierung auf die Streamerform des Stroms nicht selektiert wurden.

\subsection{Feature-Importance und physikalische Interpretation}

\section{Ergebnisse der Eventlängen-Vorhersage}

\subsection{Charakterisierung der Vorläufersignaturen}
In \figref{fig:all-event-slices} sind die Vorläufersignaturen der Ströme für die noch nicht betrachteten Datensätze DS3, DS4 und DS5 aufgetragen.
Neben den Entladungen für die ein Ende der Vorläufersignatur bestimmt werden kann, liegen die meißten Signaturen so nahe am Start des Events, dass somit sich diese nicht für eine Vorhersage des Events bzw. des Abstandes eignen. Dieses Interval vor dem Eventstart eignet sich um zu untersuchen ob der Verlauf vor dem Start des Events sich eignet um Eigenschaften von diesem insbesondere die Eventlänge zu bestimmen. Es wird das Interval \SIrange{2e-9}{3e-8}{\second} aus \figref{fig:histogram-eventdistance} betrachtet. In \figref{fig:event_left_current_sliece} ist der Verlauf des Stroms in diesem Intervall dargestellt. Die Signaturen in diesem Intervall zeigen eine Frequenz von \SI{10}{\mega\hertz} in ihren Schwingungen. Die verschiedenen Ströme in der dargestellten Stichprobe folgen alle einer solchen Oszillation vor dem Eventstart. Für einige der Ströme sind noch Subschwingungen zuerkennen, die eine Frequenz von ca. \SI{100}{\mega\hertz} besitzen.  

Neben der linken Region mit den kurzen Eventabständen aus \figref{fig:histogram-eventdistance} wird nun die rechte mit den längeren Eventabständen in dem Intervall \SIrange{3e-8}{1e-5}{\second} betrachtet. In \figref{fig:event-right-current_sliece} ist eine Stichprobe der Ströme in diesem Intervall vor dem Event dargestellt. Es sind num mehr Verläufe erkennbar, für die der Strom nicht mehr vollständig aufgelöst werden kann, beim Start des Events. Vor dem Eventstart. Der Verlauf des Stroms vor dem Event zeigt nun eine größere Varianz an Signaturen auf. Es liegen sowohl Oszillationen von \SI{10}{\mega\hertz} als auch von \SI{100}{\mega\hertz} vor. 

Neben den durch die Histogramme in \secref{sec:eventdistance} motivierten Datensätzen wurde für den DS5 das Interval \SI{1}{\micro\second} vor dem Event selektiert. In \figref{fig:1mus-current-sliece} ist der Verlauf der Ströme in diesem Interval dargestellt. Wie zu erwarten ergeben sich sowohl Oszillationen, wie in den DS1-4 aber auch flache Verläufe, für die keine Vorläufersignaturen erkannt wurden. 


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_left_peak_event_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:event_left_current_sliece}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_right_peak_event_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:event-right-current_sliece}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_1mus_ts_df.pdf}
        \caption{Verlauf des Stromes \SI{1}{\micro\second} vor dem Eventstart}
        \label{fig:1mus-current-sliece}
    \end{subfigure}
    \caption{Gegenüberstellung der relevanten Signaturverläufe}
    \label{fig:all-event-slices}
\end{figure}

\subsection{Datensatz DS1 und DS2}

\subsubsection{DS1: Automatische Segmentierung}
Der Länge einer Entladung ist von Intresse, da diese die Zeit bestimmt, in der das System durch diese gestört ist. In \figref{fig:prec_ts_event_duration_box} ist die Verteilung der Eventlängen dargestellt, sie liegen alle in einem Intervall von \SIrange{5}{20}{\micro\second} ohne dass ein linearer Trend ersichtlich ist.

\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_prec_ts_event_duration_box.pdf}
      \caption{Verteilung des Eventlänge}
      \label{fig:prec_ts_event_duration_box}
\end{figure}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
Random Forest & Eventlänge & 0,11 & $1{,}43 \times 10^{-11}$ & $3{,}78 \times 10^{-6}$ & $3{,}05 \times 10^{-6}$ \\
MLP & Eventlänge & 0,17 & $1{,}33 \times 10^{-11}$ &  \\
\bottomrule
\end{tabular}%
}
\end{table}



\subsubsection{DS2: Manuelle Streamer-Segmentierung}

Die Eventlänge verteilt sich über ein Intervall von \SIrange{5}{22}{\micro\second} für diese Teilmenge der Entladungen. Es ist kein offensichlicher Trend in den Daten zuerkennen, somit ist auch hier von intresse wie gut diese Daten durch statistische Modelle beschrieben werden können. In \tabref{tab:streamer_event_duration} sind die Ergebnisse von verschiedenen Modellen dargestellt. Das beste Modell für diese Zielvariable ist das SVR bei einer Wahl von den top \(200\) Featuren. Ein \(R^2 = 0,372\) zeigt, dass das beste Modell nur 37\% der Varianz der Eventlänge wiedergeben kann. Ein MAE von \SI{2,01}{\micro\second} zeigt jedoch, dass der mittlere Fehler im Vergleich zum Interval der Zielvariable eher klein ist. Die Mittelwerte der Eventlänge liegen in einem Intervall von \SI{7}{\micro\second}, so dass das Verwendete Modell, zumindest die Eventlänge eingrenzen kann. Ein weiterer Blick auf die Modelle zeigt, dass der MAE für den Random Forest Regressor der kleinste ist mit einem Werte von \SI{1,94}{\micro\second}, somit zeigt diese dass der \(R^2\) nicht die einzige Metrik ist die zu beachten ist.

\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_streamer_hand_event_duration_box.pdf}
      \caption{Verteilung des Eventlänge}
      \label{fig:streamer_hand_event_duration_box}
\end{figure}



\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\label{tab:streamer_event_duration}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
SVR (k=50) & Eventlänge & 0,318 & $7{,}04 \times 10^{-12}$ & $2{,}65 \times 10^{-6}$ & $2{,}00 \times 10^{-6}$ \\
Random Forest (k=100) & Eventlänge & 0,328 & $6{,}94 \times 10^{-12}$ & $2{,}63 \times 10^{-6}$ & $1{,}94 \times 10^{-6}$ \\
Elastic Net (k=100) & Eventlänge & 0,337 & $6{,}84 \times 10^{-12}$ & $2{,}62 \times 10^{-6}$ & $1{,}98 \times 10^{-6}$ \\
MLP Regressor (k=200) & Eventlänge & 0,351 & $6{,}70 \times 10^{-12}$ &  &  \\
MLP Regressor (k=100) & Eventlänge & 0,352 & $6{,}69 \times 10^{-12}$ &  &  \\
SVR (k=100) & Eventlänge & 0,365 & $6{,}56 \times 10^{-12}$ & $2{,}56 \times 10^{-6}$ & $1{,}95 \times 10^{-6}$ \\
SVR (k=200) & Eventlänge & 0,372 & $6{,}48 \times 10^{-12}$ & $2{,}55 \times 10^{-6}$ & $2{,}01 \times 10^{-6}$ \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection{DS3: Automatische segmentierte Vorläufer im Interval \SIrange{2e-9}{3e-8}{\second}}

In \figref{fig:event_left_event_duration_box} ist die Verteilung der Eventlängen für den Datensatz dargestellt. Sie liegen in einem Intervall von \SIrange{3}{30}{\micro\second}, wobei die Mittelwerte für die einzenlen Spaltabstände in einem Interval von \SIrange{7}{20}{\micro\second} liegen. Der Vergleich mit \figref{fig:streamer_hand_event_duration_box} zeigt, dass die maximale Länge die ein Event annehmen kann, für diesen Datensatz etwa \SI{10}{\micro\second} größer ist. Diese längeren Events treten für die Spaltabstände \SIrange{6}{7}{\milli\meter} auf, wobei die \SI{6}{\milli\meter} in dem Streamer Datensatz nicht vorhanden war. Somit deutet das darauf hin, dass längere Vorläufersignaturen nicht auch einem längeren Event entsprechen. In \tabref{tab:short_event_duration} sind verschiedene Modelle mit deren Metriken für diese Zielvariable dargestellt. Das mit Abstand am besten perfromente Modell ist der Random Forest mit den top 100 Featuren. Mit einem \(R^2 = 0,72\) und insbesondere einem MAE von \SI{0,69}{\micro\second} ist es das beste Modell. Insbesondere dieser kleine MAE für ein solch Großes Interval der Zielvariable ist beeindruckend gut. Dies deutlich bessere Performance als für den Streamer Datensatz ist jedoch auffällig. Eine Erklärung ist, dass diese Features direkt vom Start des Events stammen und somit Features der Form des Eventstart beinhalten und somit Auskunft geben über die Form und den Typen dieses Events. Somit zeigt dies insbesondere das die verschiedenen Längen eines solchen Entladungsevents auch zu verschiedenen Formen gehöhren.

\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_left_peak_event_distance_ts_auto_event_duration_histo.pdf}
      \caption{Verteilung der Eventlänge}
      \label{fig:event_left_event_duration_box}
\end{figure}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\label{tab:short_event_duration}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{k} \\
\midrule
Random Forest & Eventlänge & 0,76 & $9{,}01 \times 10^{-12}$ & $3{,}00 \times 10^{-6}$ & $0{,}69 \times 10^{-6}$ & 100\\
SVR & Eventlänge & 0,73 & $1{,}03 \times 10^{-11}$ &  $3{,}21 \times 10^{-6}$ & $2{,}23 \times 10^{-6}$ & 100\\
GBR & Eventlänge & 0,72 & $1{,}06 \times 10^{-11}$ &  $3{,}26 \times 10^{-6}$ & $2{,}36 \times 10^{-6}$ & 100\\
MLP & Eventlänge & 0,69 & $1{,}17 \times 10^{-11}$ & & 100\\
ElasticNet & Eventlänge & 0,49 & $1{,}95 \times 10^{-11}$ &  $4{,}42 \times 10^{-6}$ & $3{,}83 \times 10^{-6}$ & 100 \\

\bottomrule
\end{tabular}%
}
\end{table}




\subsection{DS4: Automatische segmentierte Vorläufer im Interval \SIrange{3e-8}{1e-5}{\second}}

In \figref{fig:event_right_event_duration_box} ist die Verteilung der Eventlängen gegen die Spaltabstände aufgetragen. Die Eventlängen liegen in einem Interval von \SIrange{7}{50}{\micro\second} der Vergleich mit den \figref{fig:event_left_event_duration_box} und mit \figref{fig:streamer_hand_event_duration_box} zeigen, dass somit für diesen Datensatz die Größten Eventlängen vorliegen. In dem Boxplot ist jedoch zu erkennen, dass diese Werte über \SI{30}{\micro\second} als Ausreißer makiert wurden. Somit sind nur einzelne Entladungen so viel länger. Die Mittelwerte der Eventlängen in einem Interval von \SIrange{7}{22}{\micro\second} liegen und somit in einem Bereich wie für die anderen Datensätze. In \tabref{tab:long_event_duration} sind die Ergebnisse verschiedener statistischer Modelle für die Eventlänge dargestellt. Der Random Forest ist wie auch schon für \secref{sec:short_event_duration} das am bestem performende Modell. Auch der \(R^2 = 0,73\) stimmt mit dem \(R^2 = 0,72\) des Datensatzes mit den kurzen Eventabständen überein. Nur der MAE ist mit \SI{2,53}{\micro\second} deutlich größer. Jedoch unterscheiden sich auch der RMSE mit \SI{3,56}{\micro\second} und der RMSE des anderen Datensatzes mit \SI{3}{\micro\second} nicht sonderlich von einander. Diese ähnliche Performance des Modells für diese beiden verschiedenen Datensätze, die keinen Überlapp haben, deutet darauf hin, wie auch schon in \secref{sec:short_event_duration}, dass für die Vorhersage von Eventeigenschaften, nicht die vorlaufenden Ströme relevant sind, sonder der mit im Datensatz vorhandene Start des Events. Zum dem folgt daraus, dass die beiden Datensätze in der Form der Evente ähnlich sind. Dies war auch mit der statistischen Natur dieser Event zu erwarten.

\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_right_peak_event_distance_ts_auto_event_duration_histo.pdf}
      \caption{Verteilung der Eventlänge}
      \label{fig:event_right_event_duration_box}
\end{figure}


\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\label{tab:long_event_duration}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} \\
\midrule
Random Forest & Eventlänge & 0.73 & $1.27 \times 10^{-11}$ & $3.56 \times 10^{-6}$ & $2.53 \times 10^{-6}$ \\
Gradient Boosting & Eventlänge & 0.71 & $1.36 \times 10^{-11}$ & $3.68 \times 10^{-6}$ & $2.62 \times 10^{-6}$ \\
MLP & Eventlänge & 0.59 & $1.89 \times 10^{-11}$ &  &  \\
SVR & Eventlänge & 0.32 & $3.16 \times 10^{-11}$ & $5.62 \times 10^{-6}$ & $4.18 \times 10^{-6}$ \\
\bottomrule
\end{tabular}%
}
\end{table}




\subsection{DS5: Automatische segmentierte Features \SI{1}{\micro\second} vor dem Eventstart}






\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_right_peak_event_distance_ts_auto_event_duration_histo.pdf}
      \caption{Verteilung der Eventlänge}
      \label{fig:1mus-event-duration-box}
\end{figure}







