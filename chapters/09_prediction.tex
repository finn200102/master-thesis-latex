\chapter{Vorhersage von Entladungscharakteristika}
\label{chap:prediction}

\section{Zielsetzung und Hypothesen}

\subsection{Motivation und Problemstellung}
Die frühzeitige Vorhersage von Entladungscharakteristika in Gasentladungen ist von fundamentaler Bedeutung für die Entwicklung von Schutzsystemen und das Verständis der zugrundeliegenden physikalischen Prozesse. Vorläufersignaturen die vor dem eigentlichen Entladungsevent auftreten, enthalten potentiell Infromationen über die nachfolgende Entladung. Entschieden wurde sich für eine automatische Extraktion relevanter Merkmale aus den hochdimensionalen Zeitreihendaten der Vorläuferströme und der nachfolgenden Identifikation von relevanten Featuren. Dieser Ansatz hat den Vorteil gegenüber einer manuellen Definition von Featuren, dass die Gefahr relevante Muster zu übersehen reduziert wird.
\subsection{Zielsetzung}
Die Ziele für diese Untersuchung sind die Vorhersage kritischer Entladungsparameter, dem Vorläuferabstand \(t_{prec}\) und der Eventlänge \(t_{event}\). Dies soll zur Identifikation physikalisch interpretierbarer Prädikatoren führen, also den wichtigsten Featuren für die verwendeten Zielvariablen und der Vergleich von verschiedenen ML-Algorithmen zur Identifikation des optimalen Modells.
\subsection{Forschungshypothesen}
Die folgenden Hypothesen wurden basierend auf der physikalischen Theorie von Gasentladungen aufgestellt:

\textbf{H1: Prädiktivität der Vorläufersignaturen}\newline
Die Charakteristika der Vorläufersignatur korrelieren signifikant mit dem zeitlichen Abstand zum Hauptevent.\newline
Die Vorläuferphase repräsentiert die Entlwicklung eine leitfähigen Kanals. Die Dynamik dieser Charakteristika sollte messbar sein.\newline

\textbf{H2: Frequenzabhängigkeit}\newline
Hochfrequenze Oszillationen im Megahertzbereich im Vorläuferstrom sind die stärksten Prädiktoren für den Vorläuferabstand.\newline
Auftretende Resonanzphänomene im sich entwickelnden Plasmakanal, die Dynamik diesr sollte mit dem Zustand dieses Kanal korrelieren.\newline

\textbf{H3: Nichtlinearität der Zusammenhänge}\newline
Nichtlienare Modelle (Random Forest, SVR) zeigen signifikant bessere Vorhersageperformance als lineare Modelle.\newline
Die Plasmaphysik von Gasentladungen wird durch nicht lineare Prozesse dominiert (Avalanche-Effekte, Raumladungseffekte).\newline

\textbf{H4: Feature-Redundanz}\newline
Aus der großen Anzahl an initial extrahierten Featuren genügen die Top-n informativsten Features für eine optimale Vorhersageperformance.\newline
Die initial extrahierten Feature sind hochgradig korreliert, eine Reduktion sollte Overfitting vermeiden ohne Infromationsverlust.

\textbf{H5: Einfluss des Spaltabstands}\newline
Größere Spaltabstände führen zu längeren und besser vorhersagbaren Vorläuferabständen.\newline
Größere Spaltabstände erfondern längere Lawinenprozesse und die Bildung von Streamer-Prozessen ist höher, dies führt zu besseren Vorläufersignaturen.

\subsection{Methodischer Ansatz}
Diese Hypothesen werden mit den folgenden systematischen Ansätzen verfolgt. Die automatische Feature-Extraktion erfolgt über die ts-fresh python Bibliothek, hierbei werden \(> 1000\) standardisierte Zeitreihenfeatures extrahiert, somit sind Zeit und Frequenzfeatures gegeben. Die Selektion der Features erfolgt Datengetrieben auf einer univarianten Selektion basierend auf F-Statistik. Es werden systemsatisch lineare und nichtlineare Regressoren verglichen. Es erfolgt eine Hyperparameter-Optimierung via Grid Search. Es folgt eine physikalische Interpretation der Feature-Importance.

\section{Datengrundlage und Vorverarbeitung}
\subsection{Übersicht der Datensätze}
Aus den aufgezeichneten Gasentladungen wurden verschiedene Datensätze gebildet, dabei bei waren die beiden Metriken Vorläuferstart und Vorläuferende relevant.

\begin{table}[h!]
\centering
\caption{Übersicht der verwendeten Datensätze}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c c}
\toprule
\textbf{Datensatz} & \textbf{Segmentierung} & \textbf{Zeitintervall} & \textbf{n} & \textbf{n} & \textbf{Vorläuferabstand} & \textbf{Eventlänge} \\
\midrule
DS1 & automatisch & Vorläuferstart-Ende & \~193 & x & x \\ 
DS2 & manuell & Vorläuferstart-Ende & \~142 & x & x \\
DS3 & automatisch & \SIrange{2e-9}{3e-8}{\second} & & & x \\ 
DS4 & automatisch & \SIrange{3e-8}{1e-5}{\second} & & & x \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection{Datensatz-Spezifikationen}

\textbf{DS1: Automatische segmentierte Vorläufer mit Vorläuferende}\newline
Für diesen Datensatz wurden alle Entladungen selektiert, für die die automatisch gesetzten Vorläuferstart und Vorläuferendewerte eine Differenz größer als \SI{100}{\nano\second} beträgt. Also die Länge der Vorläufersignatur länger als \SI{100}{\nano\second} ist. Es wurden so 193 Entladungen selektiert.

\textbf{DS2: Manuell segmentierte Streamer}\newline
Für diesen Datensatz wurden die Entladungen händisch selektiert, für die ein klares Vorläuferende vorliegen und die eine Streamer ähnlichen Verlauf aufweisen. Es wurden so 142 Werte selektiert.

\textbf{DS3: Automatische segmentierte Vorläufer im Interval \SIrange{2e-9}{3e-8}{\second}}

\textbf{DS4: Automatische segmentierte Vorläufer im Interval \SIrange{3e-8}{1e-5}{\second}}

\subsection{Feature-Extraktion mittels tsfresh}
Die Python-Bibliothek tsfresh (Time Series Feature extraction based on Scalable Hypothesis Tests) berechnet automatisch Hunderte von Merkmalen (Features) aus Zeitreihen. Es werden einfache Kennzahlen wie der Mittelwert, Varianz oder Schiefe, aber auch komplexere Maße wie Autokorrelation und Fourier-Koeffizienten berechnet. Die Bibliothek bietet auch Verfahren zur Auswahl relevanter Merkmale mittels statischer Hypothesentests an. Diese Bibliothek eignet sich für große Datensätze.


\subsection{Datenvorverarbeitung}

\textbf{Behandlung fehlender Werte}\newline
Nach der Extraktion der Features für einen Datensatz werden diese auf NaN-Werte untersucht, es wenn ein Feature mit NaN gefunden wurden, wird dieses Feature für alle Entladungen entfernt.

\textbf{Normalisierung}\newline
Es werden alle Features auf \(\mu = 0, \sigma = 1\) standardisiert. Dies führt zu einer gleichen Skala für alle Features, viele Algorithmen sind sensitiv gegenüber den Größenordnungen der Eingabevariablen. Dies ermöglicht ebenfalls ein höhere numerische stabilität.
% Python code ?

\subsection{Feature-Selektrion}

Die initiale Menge an Features von \(> 1000\) wurde systematisch reduziert, durch die Verwendung der univariaten Selektion. Es wurde die scikit-learn Python-Bibliothek verwendet um dessen SelectKBest Funktion zu verwenden. Es werden verschiedene Training-Runs durchgeführt für verschiedene k.% Python code?

\subsection{Train-Test-Aufteilung}
Die Modellvaliderung erfolgt über ein Test-Train Split von 20\% Test-Daten und 80\% Train-Daten. Für kleine Datenmengen gehen so jedoch viele nützliche Trainings-Daten verloheren, die Kreuzvalidierung ermöglicht dies zu kompensieren.


\section{Ergebnisse der Vorläuferabstand-Vorhersage}

\subsection{Charakterisierung der Vorläufersignaturen}
In \figref{fig:comparison_precursor_streamer} sind für DS1 und DS2, also die beiden Datensätze die sich zur Vorhersage des Vorläuferabstandes eignen, die Ströme aus denen die Features extrahiert wurden dargestellt. In \figref{fig:precursor_current_sliece} sind drei Beispiele des Vorläuferstroms zwischen Vorläuferstart und Vorläuferende dargestellt. Es ist zu erkennen, dass alle Vorläufer unter diesen Bedingungen einen ähnlichen periodischen gedämpften Verlauf besitzen die ist ähnlich zu einem wie in \secref{sec:critpoint} erwarten Warnsignal vor einem Übergang des Systems.  Es lässt sich eine Periode von ca. \SI{10}{\nano\second} erkennen und damit eine Frequenz von \SI{100}{\mega\hertz}.

Neben den automatisch bestimmten Grenzen wurden für die längeren Entladungen auch händische Grenzen für den Vorläuferstart und das Vorläuferende gesetzt. In \figref{fig:streamer_current_sliece} sind die Vorläufersignaturen die händisch makiert wurden dargestellt. Ein Vergleich mit \figref{fig:precursor_current_sliece} zeigt einen ähnlichen Verlauf, was zu erwarten war, da die gleiche Strategie verfolgt wurde. Die einzelnen Amplituden unterscheiden sich in dieser Stichprobe untereinander, jedoch ist dies nur eine kleine Stichprobe. Die Periode der einzelnen Ströme liegt ebenfalls im \SI{100}{\mega\hertz} Bereich, wobei neben dieser feinen Struktur noch gröbere auftreten von ca. \SI{10}{\mega\hertz}.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_prec_ts_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:precursor_current_sliece}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_streamer_hand_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:streamer_current_sliece}
    \end{subfigure}
    \caption{Vergleich der Verläufe der Vorläufersignatur}
    \label{fig:comparison_precursor_streamer}
\end{figure}

\subsection{Datensatz DS1: Automatische Segmentierung}

\subsubsection{Verteilung der Zielvariable}
Aufgrund des großen Abstandes dieser Vorläufer, eignet sich dieser zum Test der These, dass der Strom vor der Entladung mit dem Start der Entladung korreliert und ob sich eine solche Vorläufersignatur eignet um den Abstand zum Event vorherzusagen. In \figref{fig:prec_ts_prec_distance_box} stellt die Verteilung der Vorläuferabstände über die Spaltabstände dar. Die Mittelwerte der Vorläuferabstände für all bis auf die \SI{20}{\milli\meter} liegen verteilt um die \SI{1}{\micro\second} mit einigen Ausreißern für die \SI{10}{\milli\meter} und die \SI{11}{\milli\meter}. Für die \SI{20}{\milli\meter} liegen die meißten längeren Vorläuferabstände vor und zugleich liegt auch der Mittelwert für diese weit oben. Dies deutet darauf hin, dass es ab dem Wert die Wahrscheinlichkeit für die Bildung solch langer Vorläuferabstände signifikant ansteigt.


\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_prec_ts_precursor_distance_box.pdf}
      \caption{Verteilung des Vorläuferabstandes}
      \label{fig:prec_ts_prec_distance_box}
\end{figure}

\subsubsection{Modellperformance}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Vorläuferabstände}
\label{tab:prec_distance}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
LinearRegression & Vorläuferabstand & -0,06 & $1{,}75 \times 10^{-12}$ & $1{,}32 \times 10^{-6}$ & $1{,}04 \times 10^{-6}$ \\
RandomForestRegressor & Vorläuferabstand & -0,17 & $1{,}94 \times 10^{-12}$ & $1{,}39 \times 10^{-6}$ & $0{,}35 \times 10^{-7}$ \\

\bottomrule
\end{tabular}%
}
\end{table}

\subsubsection{Analyse}
\label{sec:ds1ana}
In \tabref{tab:prec_distance} sind die gefitteten Modelle für den DS1 Datensatz dargestellt. Das beste Modell ist die LinearRegression mit \(R^2 = -0,06\), jedoch bedeuten ein \(R^2 < 0\), dass das Modell schlechter performt als der Mittelwert des Datensatzes. Dies zeigt, dass sowohl das lineare also auch das nicht lineare Modell nicht den Datensatz wiedergeben können. Die Betrachtung des MAE als alternativen Qualitätsmaß zeigt für den RandomForestRegressor einen deutlich kleineren Wert als für die nach dem \(R^2\) Maß besserem linearen Modell. Hierbei ist zu beachten das der \(R^2\) auch wie der MSE sensitiv auf Ausreißer ist und somit der Anteil an Ausreißern in diesem Datensatz DS1, der kleiner als der DS2 Datensatz ist, groß ist. Die Betrachtung von \figref{fig:prec_ts_prec_distance_box} zeigt, dass das Plottingverfahren des Boxplots 18 Entladungen als Ausreißer makiert hat, dass sind 9,3\% des Datensatzes, somit könnten diese Verantwortlich für die schlechte Performance des Modells sein. Der Vergleich mit dem größeren Datensatz DS2 für diese Zielvariable ist nun von Intresse.

\subsection{Datensatz DS2: Manuelle Streamer-Segmentierung}

\subsubsection{Verteilung der Zielvariable}

In \figref{fig:streamer_hand_prec_distance_box} ist die Verteilung der Vorläuferabstände für die händische Setzung dargestellt. Die Verteilung der Abstände unterscheidet sich zu den automatisch gesetzten Grenzen nicht sonderlich, es ist nur zuerkennen, das für einen kleineren Anteil die Grenzen gesetz wurden. Die Werte liegen ebenfalls im Interval \SIrange{0}{8}{\micro\second}. 
\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_streamer_hand_precursor_distance_box.pdf}
      \caption{Verteilung des Vorläuferabstandes}
      \label{fig:streamer_hand_prec_distance_box}
\end{figure}

\subsubsection{Modellperformance}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Vorläuferabstände}
\label{tab:streamer_prec_distance}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
Random Forest & Vorläuferabstand & 0,55 & $6{,}63 \times 10^{-12}$ & $2{,}57 \times 10^{-6}$ & $1{,}60 \times 10^{-6}$ \\
SVR & Vorläuferabstand & 0,40 & $8{,}91 \times 10^{-12}$ &  \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsubsection{Analyse}
In \tabref{tab:streamer_prec_distance} sind die verschiedenen gefitteten Modelle dargestellt. Das am besten performente Model mit einem \(R^2 = 0.55\) ist der Random Forest, die genaue Wahl an Parametern wurde mit einem Gridsearch optimiert. Es ist an diesem Wert direkt erkenntlich, dass das Model Teile des Systems wiederspiegelt, jedoch nur etwa 55\% der Varianz der Zielvariable. Das Modell hat einen MAE von \SI{1,6}{\micro\second}, somit lässt sich aus der oberen Angabe des Intervalls des Vorläuferabstandes schließen, dass Zielvariable nur begrenzt gut aus den Featuren des Stroms \figref{fig:streamer_current_sliece} bestimmt werden kann. Insbensondere ist zu beachten, dass mehrheitlich kleinere Vorläuferabstände vorliegen, \figref{fig:histogram-precdistance} zeigt diesen linear fallenden Trend. Der MSE mit einem Wert von \SI{2,57}{\micro\second} ist etwas größer da diese Metrik Ausreißer stärker bestraft, der Blick auf \figref{fig:streamer_hand_prec_distance_box} zeigt, dass für einen Spaltabstand von \SI{2}{\centi\meter} der Mittelwert dieser Messungen deutlich über den anderen liegt, zudem sind die Vorläuferabstände für die anderen Spaltabstände um den Mittelwert über ein größeres Intervall verteilt, somit vergrößern diese Ausreißer diese Fehlermetrik etwas.
.

\subsection{Vergleichende Analyse}
\label{sec:ds12ana}
Der Vergleich der beiden Datensätze DS1 und DS2 für die Zielvariable des Vorläuferabstandes zeigt eine deutlich unterschiedliche Performance der Modelle. Für den DS1 Datensatz kann kein Modell nach dem \(R^2\) Wert die Zielvariable besser als die einfache Mittelwertbildung vorhersagen. Für den DS2 Datensatz, kann nach dieser Metrik jedoch für das beste Modell ca. 55\% der Varianz der Verteilung dieser Zielvariable erklären. Die Betrachtung anderer Metriken führt jedoch zu einem anderen Schluss, der MAE der nicht auf Ausreißer sensitiv ist für das nicht lineare Modell mit einem Wert von \(0{,}35 \times 10^{-7}\) kleiner als der kleinste MAE des DS2 Datensatzes mit \(1{,}60 \times 10^{-6}\). Dabei ist zu beachten, dass sich die Verteilung der Vorläuferabstände zwischen diesen beiden Datensätzen darin unterscheidet, dass für den DS1 Datensatz viele kurze Abstände auftreten und wenig lange, die für diesen dann oft als Ausreißer behandelt werden. Somit ist der kleinere MAE teilweise dem geschuldet, jedoch wie in \secref{sec:ds1ana} schon diskutiert, ist ein weiterer Aspekt das Verhältnis an Ausreißern die eine Größenordnungen größer als die anderen kleinern Vorläuferabstände sind. Die manuelle Wahl der Grenzen ermöglicht für den DS2, dass längere Vorläuferabstände, die durch die automatische Setzung der Grenzen nicht erkannt wurden, vermehrt auftreten und kleinere Abstände zusätzlich wegen der Fokussierung auf die Streamerform des Stroms nicht selektiert wurden. In \tabref{tab:prec_distance_filtered} wurden die Modelle trainiert auf einem modifizierten DS1 mit Vorläuferabstände größer als \SI{1}{\micro\second}. Für diesen Datensatz liegen 82 Entladungen vor. Die Modelle die auf diesen Teil von DS1 trainiert wurden zeigen eine deutlich bessere Performance, das beste Modell hier ist die lineare Regression mit 5 features mit einem \(R^2=0,23\), es können nun also ca. 23\% der Varianz des Vorläuferabstandes für diesen Datensatz erklärt werden. 
In \tabref{tab:prec_distance_filtered_2} sind die Trainingsergebnisse für die alternative Modifikation von DS1 dargestellt, also für Vorläuferabstände kleiner als \SI{1}{\micro\second}. Es ergeben sich 106 Entladungen für diese Modifikation. Es ist wie für den vollständigen DS1 zu erkennen, das die Modelle die Zielvariable nicht wiedergeben können bzw. nicht besser als die Mittelwertbildung bzw. schlechter. Somit ist die so viel schlechtere Performance für die Vorhersage von dem Vorläuferabstand mit DS1 damit zu erklären, dass dieser Datensatz sehr viele Vorläufersiganturen enthält die direkt vor dem Event liegen und somit viele kurze Vorläuferabstände. Im DS2 Datensatz wurden explizit Vorläufersiganturen gewählt die eine Streamer ähnlichen Verlauf aufweisen. Somit folgt, dass sich der Verlauf des Strom im Intervall Vorläuferstart und Vorläuferende, wenn diese klar zu definieren sind, wenn der Abstand zum Event groß genug ist, dass diese klar von einander getrennt sind und nicht in einander übergehen, verwenden lässt um den Abstand hin zum Event, also im Falle von Streamern der sich noch zu thermalisierende Streamerkanal, vorherzusagen. Somit ist die \textbf{H1: Prädiktivität der Vorläufersignaturen} - Hypothese für die Vorläufersignaturen, die Streamer förmig sind bzw. einen Vorläuferabstand größer als \SI{1}{\micro\second} aufweisen bestätigt. Für Vorläuferabstände kleiner als \SI{1}{\micro\second}, also welche die direkter ins Event übergehen, ist die \textbf{H1} - Hypothese wiederlegt. Für den DS2 mit der besten Performance der Modelle beschreiben nicht lineare Modelle die Zielvariable am besten, für den DS1 zeigen jedoch lineare Modelle die beste Performance insbesondere die Top 5 features sind hier besonder Aussage kräftig. Somit lässt sich die \textbf{H3: Nichtlinearität der Zusammenhänge} - Hypothese nicht vollständig wiederlegen oder belegen. Jedoch ist der DS2 Datensatz größer und die Modelle performen am besten für diesen, somit lässt sich die \textbf{H3} für Streamerartige Verläufe bestätigen. Aus den über 1000 extrahierten Features mit tsfresh wurden die top n features mit Hilfe der F-Statistik extrahiert und für veschiedene n trainiert. Die am besten performenten Modelle, wenn es die nicht linearen sind, verweden wie für den DS2 ca. 100, für den DS2 insbesondere den modifizierten in \tabref{tab:prec_distance_filtered} performen die linearen Modelle mit den top 5 features am besten. Die bestätigt somit die \textbf{H4: Feature-Redundanz} - Hypothese im Bezug auf die Zielvariable des Vorläuferabstandes. 


\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Vorläuferabstände für modifizierten DS1}
\label{tab:prec_distance_filtered}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c c}
\toprule                                                                                       \textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ & \textbf{k} \\
\midrule
MLPRegressor & Vorläuferabstand & 0,08 & $4{,}34 \times 10^{-12}$ & -- & -- & 100 \\
RandomForestRegressor & Vorläuferabstand & 0,12 & $4{,}13 \times 10^{-12}$ & $2{,}03 \times 10^{-6}$ & $1{,}58 \times 10^{-6}$ & 100 \\
RandomForestRegressor & Vorläuferabstand & 0,13 & $4{,}07 \times 10^{-12}$ & $2{,}02 \times 10^{-6}$ & $1{,}54 \times 10^{-6}$ & 5 \\
LinearRegression & Vorläuferabstand & 0,23 & $3{,}61 \times 10^{-12}$ & $1{,}90 \times 10^{-6}$ & $1{,}40 \times 10^{-6}$ & 5 \\
\bottomrule
\end{tabular}%
}
\end{table}


\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Vorläuferabstände für modifizierten DS1}
\label{tab:prec_distance_filtered_2}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ & \textbf{k} \\
\midrule
LinearRegression & Vorläuferabstand & 0,02 & $1{,}69 \times 10^{-14}$ & $1{,}30 \times 10^{-7}$ & $1{,}04 \times 10^{-7}$ & 5 \\
ElasticNet & Vorläuferabstand & -0,00 & $1{,}72 \times 10^{-14}$ & $1{,}31 \times 10^{-7}$ & $1{,}06 \times 10^{-7}$ & 5 \\
GradientBoostingRegressor & Vorläuferabstand & -0,04 & $1{,}80 \times 10^{-14}$ & $1{,}34 \times 10^{-7}$ & $1{,}06 \times 10^{-7}$ & 5 \\
SVR & Vorläuferabstand & -0,16 & $1{,}99 \times 10^{-14}$ & $1{,}41 \times 10^{-7}$ & $1{,}12 \times 10^{-7}$ & 5 \\
\bottomrule
\end{tabular}%
}
\end{table}



\subsection{Feature-Importance und physikalische Interpretation}
\label{sec:featimp-distance}
In \tabref{tab:ds1-features} sind die top 5 Features des am besten perfomenten Modells, der LinearRegression, dargestellt. Nur zwei der Features haben einen p-Wert größer 0, dies passt zu der Beobachtung der in \secref{sec:ds12ana} diskutierten Beobachtung, dass die Modelle für den DS1 Datensatz, diesen nicht gut wiedergeben können. Der beste Koeffizient mit einem p-Wert von 0,68 ist der imaginäre Teil des dritte Fourier-Koeffizienten. Der Imaginäreteil beschreibt die Phase und die Struktur der Vorläufersignatur. Über die folgende Formel lässt sich die Frequenz dieses Koeffizienten bestimmen:
\begin{equation}
 f_k = \frac{k f_s}{N}
\end{equation}
Hierbei ist \(f_s\) die Abtastrate, \(N\) die Anzahl an Punken im Segment und \(k\) der Index der fft. In \tabref{tab:ds1-sample} sind für die beiden auftretenden Zeitlängen und somit Abtastraten und den Vorläuferlängen die Frequenz des dritten Fourier-Koeffizienten eingetragen. Sie liegt für beide im niedrigen einstelligen MHz Bereich. Somit deutet dies auf eine Korrelation zwischen den niedrigeren Frequenzen der Vorläufer und dem Vorläuferabstand hin. Jedoch tritt diese Frequenz für den DS1 auf, für den die Modelle schlecht performt haben. 


\begin{table}[h!]
\centering
\caption{Top Extrahierte Features - LinearRegression - DS1}
\label{tab:ds1-features}
\begin{tabular}{l r}
\hline
\textbf{Feature} & \textbf{Wert} \\
\hline
current\_\_large\_standard\_deviation\_\_r\_0.35 & -0.06597 \\
current\_\_partial\_autocorrelation\_\_lag\_7 & 0.02131 \\
current\_\_change\_quantiles\_\_f\_agg\_``var''\_\_isabs\_True\_\_qh\_1.0\_\_ql\_0.8 & -0.73432 \\
current\_\_fft\_coefficient\_\_attr\_``imag''\_\_coeff\_2 & 0.68050 \\
current\_\_fft\_aggregated\_\_aggtype\_``variance'' & -0.03650 \\
\hline
\end{tabular}
\end{table}

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Zeitlänge in s} & \textbf{Anzahl} & \textbf{Abtastrate} $f_s$ & \textbf{Durchschnitt} & \(f_2\)\\
\hline
$9.9999 \times 10^{-5}$  & 162 & \SI{1}{\giga\hertz} & $5.87 \times 10^{-7}$ & \SI{3,4}{\giga\hertz}\\
$4.99995 \times 10^{-5}$ & 30  & \SI{2}{\giga\hertz} & $3.83 \times 10^{-7}$ & \SI{1,04}{\giga\hertz}\\
\hline
\end{tabular}
\caption{Zeitlängenverteilung und Statistik für den DS1}
\label{tab:ds1-sample}
\end{table}

In \tabref{tab:ds2-features} sind die top 5 features mit den höchsten p-Werten des RandomForestRegressors dargestellt. Es fällt direkt auf, dass 4 von diesen Fourier-Koeffizienten entsprechen also wieder gewissen Frequenzen entsprechen, jedoch sind diese nun deutlich höhere Koeffizienten und somit auch höhere Frequenzen. Die Welch-Dichte ist auch ein Frequenzmaß bzw. zeigt die Leistung in einem bestimmten Frequenzband auf. In \tabref{tab:ds2-sample} sind für die verschiedenen Abtastraten die Frequenzen der Fourier-Koeffizienten aufgetragen. Für den größeren Teil der Daten mit einer Abtastrate von \SI{1}{\giga\hertz} liegen die \(f_k\) Frequenzen im mittleren zweistelligen MHz Berreich mit in den niedrigen dreistelligen MHz Bereich. Für die höhere Abtastrate liegen höhere Frequenzen im dreistelligen MHz Bereich vor. Diese Größenordnungen der Frequenz mit einer hohen Korrelation zur Zielvariable passen mit denen in \figref{fig:streamer_current_sliece} beobachteten Frequenzen der Vorläufersignatur zusammen. Das für eine höhere Abtastrate auch höhere Frequenz eine Rolle spielen, deutet darauf hin, dass besonders hohe Frequenz mehr über den Abstand hin zum Ereignis und somit auch über den sich thermalisierende Streamerkanal aussagen als niedrigere. Dies ermöglicht auch die These, dass mit einer noch höheren Abtastrate von mehr als \SI{2}{\giga\hertz} auch noch höhere Frequenzen relevant werden und somit sich auch die Genauigkeit der Vorhersage verbessen könnte, wenn mit einer noch höheren Abtastrate solche Entladungen untersucht würden. 

\begin{table}[h!]
\centering
\caption{Top Extrahierte Features - RandomForestRegressor - DS2}
\label{tab:ds2-features}
\begin{tabular}{l r}
\hline
\textbf{Feature} & \textbf{Wert} \\
\hline
current\_\_fft\_coefficient\_\_attr\_\_"real"\_\_coeff\_34 & 0.3008838 \\
current\_\_fft\_coefficient\_\_attr\_\_"imag"\_\_coeff\_24 & 0.1530438 \\
current\_\_spkt\_welch\_density\_\_coeff\_8 & 0.0671714 \\
current\_\_fft\_coefficient\_\_attr\_\_"imag"\_\_coeff\_70 & 0.0615635 \\
current\_\_fft\_coefficient\_\_attr\_\_"real"\_\_coeff\_70 & 0.0594062 \\
\hline
\end{tabular}
\end{table}


\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Zeitlänge in s} & \textbf{Anzahl} & \textbf{Abtastrate} $f_s$ & \textbf{Durchschnitt} & \(f_{34}\) & \(f_{24}\) & \(f_{70}\)\\
\hline
$4.99995 \times 10^{-5}$ & 29  & \SI{2}{\giga\hertz} & $3,25 \times 10^{-7}$ & \SI{209,23}{\mega\hertz} & \SI{147,69}{\mega\hertz} & \SI{430,76}{\mega\hertz}\\
$9.9999 \times 10^{-5}$  & 112 & \SI{1}{\giga\hertz} & $6,14 \times 10^{-7}$ & \SI{55,37}{\mega\hertz} & \SI{39,08}{\mega\hertz} & \SI{114}{\mega\hertz}\\
\hline
\end{tabular}
\caption{Zeitlängenverteilung und Statistik für den DS2}
\label{tab:ds2-sample}
\end{table}




\section{Ergebnisse der Eventlängen-Vorhersage}

\subsection{Charakterisierung der Vorläufersignaturen}
In \figref{fig:all-event-slices} sind die Vorläufersignaturen der Ströme für die noch nicht betrachteten Datensätze DS3, DS4 und DS5 aufgetragen.
Neben den Entladungen für die ein Ende der Vorläufersignatur bestimmt werden kann, liegen die meißten Signaturen so nahe am Start des Events, dass somit sich diese nicht für eine Vorhersage des Events bzw. des Abstandes eignen. Dieses Interval vor dem Eventstart eignet sich um zu untersuchen ob der Verlauf vor dem Start des Events sich eignet um Eigenschaften von diesem insbesondere die Eventlänge zu bestimmen. Es wird das Interval \SIrange{2e-9}{3e-8}{\second} aus \figref{fig:histogram-eventdistance} betrachtet. In \figref{fig:event_left_current_sliece} ist der Verlauf des Stroms in diesem Intervall dargestellt. Die Signaturen in diesem Intervall zeigen eine Frequenz von \SI{10}{\mega\hertz} in ihren Schwingungen. Die verschiedenen Ströme in der dargestellten Stichprobe folgen alle einer solchen Oszillation vor dem Eventstart. Für einige der Ströme sind noch Subschwingungen zuerkennen, die eine Frequenz von ca. \SI{100}{\mega\hertz} besitzen.  

Neben der linken Region mit den kurzen Eventabständen aus \figref{fig:histogram-eventdistance} wird nun die rechte mit den längeren Eventabständen in dem Intervall \SIrange{3e-8}{1e-5}{\second} betrachtet. In \figref{fig:event-right-current_sliece} ist eine Stichprobe der Ströme in diesem Intervall vor dem Event dargestellt. Es sind num mehr Verläufe erkennbar, für die der Strom nicht mehr vollständig aufgelöst werden kann, beim Start des Events. Der Verlauf des Stroms vor dem Event zeigt nun eine größere Varianz an Signaturen auf. Es liegen sowohl Oszillationen von \SI{10}{\mega\hertz} als auch von \SI{100}{\mega\hertz} vor. 

Neben den durch die Histogramme in \secref{sec:eventdistance} motivierten Datensätzen wurde für den DS5 das Interval \SI{1}{\micro\second} vor dem Event selektiert. In \figref{fig:1mus-current-sliece} ist der Verlauf der Ströme in diesem Interval dargestellt. Wie zu erwarten liegen sowohl Oszillationen, wie in den DS1-4 aber auch flache Verläufe, für die keine Vorläufersignaturen erkannt wurden, vor. 


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_left_peak_event_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:event_left_current_sliece}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_right_peak_event_df.pdf}
        \caption{Verlauf des Startes der Vorläufersignatur}
        \label{fig:event-right-current_sliece}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{../figures/maschinelearning/features_1mus_ts_df.pdf}
        \caption{Verlauf des Stromes \SI{1}{\micro\second} vor dem Eventstart}
        \label{fig:1mus-current-sliece}
    \end{subfigure}
    \caption{Gegenüberstellung der relevanten Signaturverläufe}
    \label{fig:all-event-slices}
\end{figure}

\subsection{Datensatz DS1 und DS2}

\subsubsection{DS1: Automatische Segmentierung}

\subsubsection{Verteilung der Zielvariable}
Die Länge einer Entladung ist von Intresse, da diese die Zeit bestimmt, in der das System durch diese gestört ist. In \figref{fig:prec_ts_event_duration_box} ist die Verteilung der Eventlängen dargestellt, sie liegen alle in einem Intervall von \SIrange{5}{20}{\micro\second} ohne dass ein linearer Trend ersichtlich ist. Somit scheint die Länge der auftretenden Entladungen unabhängig von dem vorliegenden Spaltabstand d. Der Vergleich mit der Verteilung der Vorläuferabstände zeigt, dass für die Eventlängen weniger Ausreißer vorliegen. Die Werte für die Spaltabstände \SI{8}{\milli\meter}, \SI{12}{\milli\meter} und \SI{13}{\milli\meter} liegen deutlich enger bei einander, haben also eine niedrigere Varianz. Dies liegt an der geringeren Anzahl an Entladungen die bei diesen Spaltabständen durchgeführt wurden und ist auch in den Verteilungen für die Vorläuferabstände zu erkennen. Anzumerken ist, dass für den Spaltabstand \SI{20}{\milli\meter} auch nur drei Entladungen vorliegen, die Verteilung der Eventlängen jedoch gut zu denen von \SI{7}{\milli\meter}, \SI{10}{\milli\meter} und \SI{11}{\milli\meter} passt.

\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_prec_ts_event_duration_box.pdf}
      \caption{Verteilung des Eventlänge}
      \label{fig:prec_ts_event_duration_box}
\end{figure}


\subsubsection{Modellperformance}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\label{tab:event_duration_ds1}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
Random Forest & Eventlänge & 0,11 & $1{,}43 \times 10^{-11}$ & $3{,}78 \times 10^{-6}$ & $3{,}05 \times 10^{-6}$ \\
MLP & Eventlänge & 0,17 & $1{,}33 \times 10^{-11}$ &  \\
\bottomrule
\end{tabular}%
}
\end{table}


\begin{table}[h!]
\centering
\caption{Modell Performance für die Vorhersage der Eventlänge für den modifizierten DS1}
\label{tab:event_duration_ds1_mod}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
Random Forest & Eventlänge & 0,466 & $1{,}13 \times 10^{-11}$ & $3{,}37 \times 10^{-6}$ & $2{,}39 \times 10^{-6}$ \\
SVR           & Eventlänge & 0,461 & $1{,}15 \times 10^{-11}$ & $3{,}38 \times 10^{-6}$ & $2{,}58 \times 10^{-6}$ \\
Gradient Boosting & Eventlänge & 0,414 & $1{,}24 \times 10^{-11}$ & $3{,}53 \times 10^{-6}$ & $2{,}63 \times 10^{-6}$ \\
\bottomrule
\end{tabular}%
}
\end{table}


\subsubsection{Analyse}

In \tabref{tab:event_duration_ds1} sind die Ergebnisse der Modelle für den DS1 Datensatz mit der Zielvariable der Eventlänge dargestellt. Das beste Modell ist hier, dass Multi Layer Perceptron (MLP), also ein kleines neuronales Netz, mit einem \(R^2 = 0,17\). Somit kann kann dieses etwa 17\% der Varianz der Zielverteilung der Eventlänge beschreiben. Interessant ist hier, dass der \(R^2\) Wert hier in der gleichen Größenordnung liegt, wie die des modifizierten DS1 Datensatzes aus \tabref{tab:prec_distance_filtered}. Die Betrachtung von \tabref{tab:event_duration_ds1_mod} zeigt jedoch, dass wenn wie in \ref{tab:prec_distance_filtered} der DS1 modifiziert wird und Modelle auf diesen für die Eventlänge trainiert werden, dass das Beste Modell nun der RandomForestRegressor mit einem \(R^2 = 0,466\) ist. Somit lässt sich die Eventlänge sowohl für den vollständigen DS1 besser als den Vorläuferabstand vorhersagen, diese Vorhersage wird aber noch deutlich besser für den modifizierten DS1, für den minimale Vorläuferabstände von \SI{1}{\micro\second} vorausgesetz werden. 




\subsubsection{DS2: Manuelle Streamer-Segmentierung}

\subsubsection{Verteilung der Zielvariable}
Die Eventlänge verteilt sich über ein Intervall von \SIrange{5}{22}{\micro\second} für diese Teilmenge der Entladungen. Es ist kein offensichlicher Trend in den Daten zuerkennen, somit ist auch hier von intresse wie gut diese Daten durch statistische Modelle beschrieben werden können. 
\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_streamer_hand_event_duration_box.pdf}
      \caption{Verteilung des Eventlänge}
      \label{fig:streamer_hand_event_duration_box}
\end{figure}



\subsubsection{Modellperformance}
\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\label{tab:streamer_event_duration}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & $\mathbf{MSE}$ & $\mathbf{RMSE}$ & $\mathbf{MAE}$ \\
\midrule
SVR (k=50) & Eventlänge & 0,318 & $7{,}04 \times 10^{-12}$ & $2{,}65 \times 10^{-6}$ & $2{,}00 \times 10^{-6}$ \\
Random Forest (k=100) & Eventlänge & 0,328 & $6{,}94 \times 10^{-12}$ & $2{,}63 \times 10^{-6}$ & $1{,}94 \times 10^{-6}$ \\
Elastic Net (k=100) & Eventlänge & 0,337 & $6{,}84 \times 10^{-12}$ & $2{,}62 \times 10^{-6}$ & $1{,}98 \times 10^{-6}$ \\
MLP Regressor (k=200) & Eventlänge & 0,351 & $6{,}70 \times 10^{-12}$ &  &  \\
MLP Regressor (k=100) & Eventlänge & 0,352 & $6{,}69 \times 10^{-12}$ &  &  \\
SVR (k=100) & Eventlänge & 0,365 & $6{,}56 \times 10^{-12}$ & $2{,}56 \times 10^{-6}$ & $1{,}95 \times 10^{-6}$ \\
SVR (k=200) & Eventlänge & 0,372 & $6{,}48 \times 10^{-12}$ & $2{,}55 \times 10^{-6}$ & $2{,}01 \times 10^{-6}$ \\
\bottomrule
\end{tabular}%
}
\end{table}


\subsubsection{Analyse}
In \tabref{tab:streamer_event_duration} sind die Ergebnisse von verschiedenen Modellen dargestellt. Das beste Modell für diese Zielvariable ist das SVR bei einer Selektion von den top \(200\) Featuren. Ein \(R^2 = 0,372\) zeigt, dass das beste Modell ca. 37\% der Varianz der Eventlänge wiedergeben kann. Ein MAE von \SI{2,01}{\micro\second} zeigt, dass der mittlere Fehler im Vergleich zum Interval der Zielvariable eher klein ist. Die Mittelwerte der Eventlänge liegen in einem Intervall von ca. \SI{7}{\micro\second}, so dass das verwendete Modell, die Eventlänge eingrenzen kann. Ein weiterer Blick auf die Modelle zeigt, dass der MAE für den Random Forest Regressor der kleinste ist mit einem Werte von \SI{1,94}{\micro\second}, somit zeigt diese dass der \(R^2\) nicht die einzige Metrik ist die zu beachten ist. Der Vergleich mit dem DS1 zeigt, dass für den DS2-Streamer-Datensatz sich die Eventlänge schlechter vorhersagen lässt. Dies was für den DS1 umgekehrt. Zu beachten ist, dass in dem Streamer Datensatz mehr Vorläufer vorliegen die einen höheren Vorläuferabstand besitzen als in DS1. Somit lässt sich diese andere Performance für eine Eventeigenschaft damit erklären, dass die Selektierten Feature soweit vor dem Eventliegen, dass diese weniger über diese Aussagen können und primär die Thermalisierung des Leitungskanals voraussagen können. Die umgekehrte Performance des DS1 lässt sich damit erklären, dass in diesem mehr dicht an dem Event liegene Signaturen vorliegen, die stärker mit dessen Eigenschaften korrelieren.



\subsection{DS3: Automatische segmentierte Vorläufer im Interval \SIrange{2e-9}{3e-8}{\second}}
\label{sec:short_event_duration}

\subsubsection{Verteilung der Zielvariable}

In \figref{fig:event_left_event_duration_box} ist die Verteilung der Eventlängen für den Datensatz dargestellt. Sie liegen in einem Intervall von \SIrange{3}{30}{\micro\second}, wobei die Mittelwerte für die einzenlen Spaltabstände in einem Interval von \SIrange{7}{20}{\micro\second} liegen. Der Vergleich mit \figref{fig:streamer_hand_event_duration_box} zeigt, dass die maximale Länge die ein Event annehmen kann, für diesen Datensatz etwa \SI{10}{\micro\second} größer ist. Diese längeren Events treten für die Spaltabstände \SIrange{6}{7}{\milli\meter} auf, wobei die \SI{6}{\milli\meter} in dem Streamer Datensatz nicht vorhanden war. Somit deutet das darauf hin, dass längere Vorläufersignaturen nicht auch einem längeren Event entsprechen. 
\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_left_peak_event_distance_ts_auto_event_duration_histo.pdf}
      \caption{Verteilung der Eventlänge}
      \label{fig:event_left_event_duration_box}
\end{figure}


\subsubsection{Modellperformance}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\label{tab:short_event_duration}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} & \textbf{k} \\
\midrule
Random Forest & Eventlänge & 0,76 & $9{,}01 \times 10^{-12}$ & $3{,}00 \times 10^{-6}$ & $0{,}69 \times 10^{-6}$ & 100\\
SVR & Eventlänge & 0,73 & $1{,}03 \times 10^{-11}$ &  $3{,}21 \times 10^{-6}$ & $2{,}23 \times 10^{-6}$ & 100\\
GBR & Eventlänge & 0,72 & $1{,}06 \times 10^{-11}$ &  $3{,}26 \times 10^{-6}$ & $2{,}36 \times 10^{-6}$ & 100\\
MLP & Eventlänge & 0,69 & $1{,}17 \times 10^{-11}$ & & 100\\
ElasticNet & Eventlänge & 0,49 & $1{,}95 \times 10^{-11}$ &  $4{,}42 \times 10^{-6}$ & $3{,}83 \times 10^{-6}$ & 100 \\

\bottomrule
\end{tabular}%
}
\end{table}


\subsubsection{Analyse}
In \tabref{tab:short_event_duration} sind verschiedene Modelle mit deren Metriken für diese Zielvariable dargestellt. Das am besten perfromente Modell ist der Random Forest mit den top 100 Featuren. Mit einem \(R^2 = 0,72\) und insbesondere einem MAE von \SI{0,69}{\micro\second} ist es das beste Modell. Insbesondere dieser kleine MAE für ein solch Großes Interval der Zielvariable ist beeindruckend gut. Diese deutlich bessere Performance als für die DS1-2 ist interessant. Eine Erklärung ist, dass diese Features direkt vom Start des Events stammen und somit zum einem mit diesem stärker korrelieren und zum anderen Features der Form des Eventstart beinhalten und somit Auskunft geben über die Form und den Typen dieses Events. Somit zeigt dies insbesondere das die verschiedenen Längen eines solchen Entladungsevents auch zu verschiedenen Formen bzw. Startverläufen gehöhren.



\subsection{DS4: Automatische segmentierte Vorläufer im Interval \SIrange{3e-8}{1e-5}{\second}}

\subsubsection{Verteilung der Zielvariable}

In \figref{fig:event_right_event_duration_box} ist die Verteilung der Eventlängen gegen die Spaltabstände aufgetragen. Die Eventlängen liegen in einem Interval von \SIrange{7}{50}{\micro\second} der Vergleich mit den \figref{fig:event_left_event_duration_box} und mit \figref{fig:streamer_hand_event_duration_box} zeigen, dass somit für diesen Datensatz die Größten Eventlängen vorliegen. In dem Boxplot ist jedoch zu erkennen, dass diese Werte über \SI{30}{\micro\second} als Ausreißer makiert wurden. Somit sind nur einzelne Entladungen so viel länger. Die Mittelwerte der Eventlängen liegen in einem Interval von \SIrange{7}{22}{\micro\second} und somit in einem Bereich wie für die anderen Datensätze. 
\begin{figure}[H]
    \centering
      \includegraphics[width=\linewidth]{../figures/maschinelearning/features_right_peak_event_distance_ts_auto_event_duration_histo.pdf}
      \caption{Verteilung der Eventlänge}
      \label{fig:event_right_event_duration_box}
\end{figure}


\subsubsection{Modellperformance}

\begin{table}[h!]
\centering
\caption{Model Performance für die Vorhersage der Eventlänge}
\label{tab:long_event_duration}
\resizebox{\textwidth}{!}{%
\small
\begin{tabular}{l c c c c c}
\toprule
\textbf{Modell} & \textbf{Zielgröße} & $\mathbf{R^2}$ & \textbf{MSE} & \textbf{RMSE} & \textbf{MAE} \\
\midrule
Random Forest & Eventlänge & 0.73 & $1.27 \times 10^{-11}$ & $3.56 \times 10^{-6}$ & $2.53 \times 10^{-6}$ \\
Gradient Boosting & Eventlänge & 0.71 & $1.36 \times 10^{-11}$ & $3.68 \times 10^{-6}$ & $2.62 \times 10^{-6}$ \\
MLP & Eventlänge & 0.59 & $1.89 \times 10^{-11}$ &  &  \\
SVR & Eventlänge & 0.32 & $3.16 \times 10^{-11}$ & $5.62 \times 10^{-6}$ & $4.18 \times 10^{-6}$ \\
\bottomrule
\end{tabular}%
}
\end{table}


\subsubsection{Analyse}
In \tabref{tab:long_event_duration} sind die Ergebnisse verschiedener statistischer Modelle für die Eventlänge dargestellt. Der Random Forest ist wie auch schon für \secref{sec:short_event_duration} das am bestem performende Modell. Auch der \(R^2 = 0,73\) stimmt mit dem \(R^2 = 0,72\) des Datensatzes mit den kurzen Eventabständen überein. Nur der MAE ist mit \SI{2,53}{\micro\second} deutlich größer. Jedoch unterscheiden sich auch der RMSE mit \SI{3,56}{\micro\second} und der RMSE des anderen Datensatzes mit \SI{3}{\micro\second} nicht sonderlich von einander. Diese ähnliche Performance des Modells für diese beiden verschiedenen Datensätze, die keinen Überlapp haben, deutet darauf hin, wie auch schon in \secref{sec:short_event_duration}, dass für die Vorhersage von Eventeigenschaften, nicht die vorlaufenden Ströme relevant sind, sonder der mit im Datensatz vorhandene Start des Events. Zu dem folgt daraus, dass die beiden Datensätze in der Form der Evente ähnlich sind. Dies war auch mit der statistischen Natur dieser Events zu erwarten.



\subsection{Vergleichende Analyse}
Die Betrachtung der DS1-4 für die Vorhersage der Eventlänge zeigt, dass sich die DS1-2 von den DS3-4 in der Modelierung der Eventlänge darin unterscheiden, dass die Qualität der Vorhersage für die DS3-4, deren Features vom Vorläuferstart bis zum Start des Events gehen, dieser erheblich besser modelieren können. Des weitern ist der Vergleich von DS1 und DS2 für die Modelierung der Eventlänge interressant. Der DS2-Streamer-Datensatz eignet sich deutlich besser zur Vorhersage der Eventlängen als der unmodifizierte DS2, dieser Unterschied lässt sich umdrehen, wenn für DS1 mindest Vorläuferabstände verwendet werden von \SI{1}{\micro\second}. Dies deutet darauf hin, dass zwar die beste Vorhersage der Eventlängen mit den DS3-4, die die Dynamik des Eventstarts mit in ihren Features besitzen, funktioniert, jedoch wenn keine Eventstartfeatures verwendet werden, sich die Features in den weiter entfernteren Vorläufern, die ein klar zu definierendes Ende besitzen, und streamer artig sind, besser eignen zur Vorhersage, als die Vorläufersignaturen die näher am Event liegen, jedoch nocht von dessen Start getrennt sind. Die bessere Eignung der D3-4 ist damit zu erklären, dass der Verlauf des Startes des Events noch zum Teil im Datensatz liegen und somit etwas über die Art der Entladung und damit auch der Länge schließen lässt. Der Unterschied zwischen DS1 und 2 und zwischen DS1 und DS1-modifiziert ist jedoch überraschend, denn es währe intuitiv zu erwarten, dass näher am Event liegen Features sich auch besser eignen um etwas über dieses Auszusagen. Ein Erklärungsansatz wäre, dass die Features des Startes des Ladungskanals einer streamer artigen Entladung einiges über die weitere Entwicklung von diesem aussagen und dass für diesen Entladungsprozess der Kanal stark mit der folgenden Dynamik des Events korrelieren. Und dass dieser Zusammenhang für nicht streamer artige Entladungen nicht vorliegt bzw. nicht so stark.


\subsection{Feature-Importance und physikalische Interpretation}
In den Tabellen \ref{tab:ds3-features} bis \ref{tab:ds1-features-ana} sind die top 5 Features der Datensätze DS1-4 für die Eventlänge eingetragen. Im letzen Abschnitt hat sich gezeigt, dass die Vorhersage der Eventlänge mit den DS3 und 4 ambesten funktioniert mit ca. \(R^2 \propto 0,7\) und den DS1 und 2 für die die Modelierung etwas schlechter funktionert. Der Vergleich der Tabellen \ref{tab:ds3-features} und \ref{tab:ds4-features} mit den Tabellen \ref{tab:ds1-features-ana} und \ref{tab:ds2-features-ana} zeigt, dass die p-Werte der top 5 Features für die DS3 und 4 kleiner sind als die der DS1 und DS2, obwohl die DS1 und DS2 schlechter moduliert werdend konnten. Dies deutet daraufhind, dass für die DS1 und DS2 es einige sehr gute Features in den Streamersignaturen gibt, jedoch die meißten Features schwächer sind. Wohingegen für die DS3 und 4 es viele signifikante Features gibt, jedoch weniger die besonders signifikant sind. Für den DS1 sind die top 5 Features alle Verhältnise an Punkten, die außerhalb eines Vielfachen der Standartabweichung liegen, es wird also wiedergeben wie oft das Signal stark vom Mittelwert abweicht. Somit wird der DS1 für die Vorhersage der Eventlänge, also einer Eventeigenschaft, durch seine Extremwerte charakterisiert. Für den DS2 sind die top 5 Features die Anzahl der Maxima in Segmenten einer gewissen Größe und Maße der Komplexität einer Zeitreihe. Die Form und der Zufall im Signal sind die stärksten Features. Die top Features des DS3 sind die Verteilung des Signals bei niedrigen Quantilen, Anteil der Punkte die 2 Standartabweichung vom Mittelwert entfernt sind und der Grundpegel des Signals. Für den DS4 sind die top Features verschiedene Maße die die Signalenergie, die Varibilität, die Komplexität und sich wiederholende Muster wiedergeben. Es sind also dynamische Eigenschaften relevant. Die DS1 und 2 sind Features die einen größeren Abstand zum Event besitzen, deshalb ist die Modelierung auch schieriger, da die implusartige, stark schwankede und durch viele lokale Maxima und Unregelmäßigkeiten charakterisierten Vorläufersignaturen auch Features entsprechen die Extremwerte bzw. Peaks und Komplexität modelieren. Die DS3 und DS4 beschreiben die Werte einschließlich denen direkt vor dem Start des Events, hier spiegel die Features die Basisverteilung(Quantile), den Grundpegel, die Energie und die Variabilität wieder. Diese eher kontinuierlichen Eigenschaften sind konsistenter und eignen sich deshalb besser für Vorhersagen der Eigenschaften des Events. Somit bilden die DS1 und DS2 also physikalische betrachtet die stochastischen, Unregelmäßige Vorphase eines Prozesses ab, während DS3 und 4 die deterministischen Startbedingungen repräsentieren. Somit sind viele Features der DS3 und DS4 gleichmäßig relevant für eine gute Modelierung, währen die DS1 und DS2 einzelne sehr starke, aber insgesamt weniger stablie Features haben. 


\begin{table}[h!]
\centering
\caption{Top Extrahierte Features - RandomForestRegressor - DS3}
\label{tab:ds3-features}
\begin{tabular}{l r}
\hline
\textbf{Feature} & \textbf{Wert} \\
\hline
current\_\_quantile\_\_q\_0.1 & 0.1006788 \\
current\_\_quantile\_\_q\_0.3 & 0.0827991 \\
current\_\_quantile\_\_q\_0.2 & 0.0607876 \\
current\_\_ratio\_beyond\_r\_sigma\_\_r\_2 & 0.0607503 \\
current\_\_linear\_trend\_\_attr\_\_"intercept" & 0.0550868 \\
\hline
\end{tabular}
\end{table}


\begin{table}[h!]
\centering
\caption{Top Extrahierte Features - RandomForestRegressor - DS4}
\label{tab:ds4-features}
\begin{tabular}{l r}
\hline
\textbf{Feature} & \textbf{Wert} \\
\hline
current\_\_abs\_energy & 0.0869079 \\
current\_\_absolute\_sum\_of\_changes & 0.0650000 \\
current\_\_sum\_of\_reoccurring\_values & 0.0622045 \\
current\_\_cid\_ce\_\_normalize\_False & 0.0461230 \\
current\_\_change\_quantiles\_\_f\_agg\_\_"var"\_\_isabs\_True\_\_qh\_0.8\_\_ql\_0.0 & 0.0418604 \\
\hline
\end{tabular}
\end{table}


\begin{table}[h!]
\centering
\caption{Top Extrahierte Features - RandomForestRegressor - DS2}
\label{tab:ds2-features-ana}
\begin{tabular}{l r}
\hline
\textbf{Feature} & \textbf{Wert} \\
\hline
current\_\_mean\_n\_absolute\_max\_\_number\_of\_maxima\_7 & 0.3952694 \\
current\_\_permutation\_entropy\_\_dimension\_4\_\_tau\_1 & 0.2085023 \\
current\_\_mean\_n\_absolute\_max\_\_number\_of\_maxima\_7 & 0.1756566 \\
current\_\_permutation\_entropy\_\_dimension\_7\_\_tau\_1 & 0.1480306 \\
current\_\_permutation\_entropy\_\_dimension\_5\_\_tau\_1 & 0.1429784 \\
\hline
\end{tabular}
\end{table}


\begin{table}[h!]
\centering
\caption{Top Extrahierte Features - LinearRegression - DS1}
\label{tab:ds1-features-ana}
\begin{tabular}{l r}
\hline
\textbf{Feature} & \textbf{Wert} \\
\hline
current\_\_ratio\_beyond\_r\_sigma\_\_r\_7 & 0.2270601 \\
current\_\_ratio\_beyond\_r\_sigma\_\_r\_7 & 0.2270601 \\
current\_\_ratio\_beyond\_r\_sigma\_\_r\_3 & 0.1894779 \\
current\_\_ratio\_beyond\_r\_sigma\_\_r\_3 & 0.1894779 \\
current\_\_ratio\_beyond\_r\_sigma\_\_r\_5 & 0.1402674 \\
\hline
\end{tabular}
\end{table}

\section{Gesamtdiskussion und Validierung der Hypothesen}

\subsection{Hypothesenvaliderung}


\textbf{H1: Prädiktivität der Vorläufersignaturen}\newline
Wie in \secref{sec:ds12ana} diskutiert gilt diese Hypothese für die Vorläufersignaturen die größere Vorläuferabstände als \SI{1}{\micro\second} besitzen und insbesondere die die eine Streamer artige Form besitzen, die Hypothese ist widerlegt für kleinere Abstände.


\textbf{H2: Frequenzabhängigkeit}\newline
In \secref{sec:featimp-distance} wurden die relevanten Features für die Vorhersage des Vorläuferabstandes behandelt, dabei waren insbesondere für den DS2, aber auch für den DS1 FFT-Features relevant, denen eine Frequenz sich zuordnen lässt, dabei ergaben sich abhängig von den Abtastraten Frequenzen im mitteleren zweistelligen bis in den niedrigen dreistelligen MHz Bereich. Dies bestätigt die Hypothese H2 für die Vorhersage des Vorläuferabstandes, dass hochfrequente Oszillationen die stärksten Prädiktoren sind. Es ist zu erwähnen dass diese Arten an Features nicht mehr für die Vorhersage der Eventeigenschaft Eventlänge relevant sind, insbesondere für die DS3 und DS4, jedoch war in der Hypothesen explitit die Rede von dem Vorläuferabstand. 


\textbf{H3: Nichtlinearität der Zusammenhänge}\newline
Wie in \secref{sec:ds12ana} diskutiert lässt sich diese Hypothesen nur für den DS2 mit den streamer artigen Entladungen bestätigen, da die nicht linearen Modelle für diesen am besten performen, jedoch kann der DS1 so modifiziert werden, dass auch für diesen die nicht-linearen Modelle das beste Ergebnis liefern. Somit liegen zwischen den Vorläufersignaturen, die mehr als \SI{1}{\micro\second} entfernt sind und dessen Features ein nicht linearer Zusammenhang mit der Zielvariable des Vorläuferabstandes vor. In dieser Hypothese wurde jedoch nicht explizit über den Vorläuferabstand gesporchen sondern allgemein über nicht-lineare Zusammenhänge, somit ist die Betrachtung der Eventlängen Vorhersage auch relevant. Die am besten performenden Modelle für die Eventlängen Regression waren alles Modelle die entweder klar nicht linear sind oder auch nicht lineare Zusammenhänge modelieren können. Somit gilt die Hypothese auch für die Eventlängen Regression.



\textbf{H4: Feature-Redundanz}\newline
Wie in \secref{sec:ds12ana} behandelt, reichen die top n Features für die Vorhersage der Zielvariablen, die Verwendung der vollen Anzahl der Features auch mit einer Technik die mit vielen Features umgehen kann, wie dem RandomForest führt zu einer sich nicht weiter verbessernden Performance oder sogar zu einer schlechteren. Somit lässt sich diese Hypothese somit vollständig bestätigen.


\textbf{H5: Einfluss des Spaltabstands}\newline
Die Hypothese, dass größere Spaltabstände zu besser sich vorhersagbaren Vorläuferabständen führt, lässt sich teilweise bestätigen. Wie in \figref{fig:prec_ts_prec_distance_box} und in \figref{fig:streamer_hand_prec_distance_box} liegt der Mittelwert der Vorläuferabstände f[r den Spaltabstand von \SI{20}{\milli\meter} deutlich höher als für die kleineren Spaltabstände. Dies deutet darauf hin, dass ab diesem Wert die Wahrscheinlichkeit für die Bildung langer Vorläuferabstände signifikant ansteigt. Jedoch ist zu beachten, dass jeweils nur eine kleine Anzahl an Entladungen in diesem Intervall liegt und dies somit noch keine klare statistische signifikant besitzt. Somit gibt es ein Indiz auf eine solch andere Performance, jedoch ist die Anzahl an Entladungen für diese größeren Abstände zu klein um eine klare Aussage zu treffen. Es lässt sich nur mit dem Vergleich von DS1 und DS2 zeigen, dass die etwas im Mittel längeren Vorläuferabstände sich besser vorhersagen lassen als die kürzeren.  

\subsection{Physikalische Interpretation}
Die Vorläuferabstände ließen sich insbesondere für die streamer artigen im DS2 mit einem \(R^2 = 0,55\) modelieren. Dies zeigt einen klaren Zusammenhang dieser Features in der Vorläufersignatur und dem Abstand zum Event bwz. der Länge der Thermalisierungsphase des Leitungskanals.

Die streamer-artigen Vorläufer mit Abständen größer \SI{1}{\micro\second} entsprechen physikalisch der Phase der schrittweisen kanalbidlung durch aufeinanderfolgende Elektronenlawinen. Die beobachteten hochfrequenten Oszillationen im mittleren zweistelligen bis zum niedrigen dreistelligen MHz Bereich entsprechen charakteristischen Plasmaresonanzen, die durch die Wechselwirkung zwischen Raumladungen, dem sich entwickelden elektrischen Feld und den oszillierenden Elektronen im Kanal entstehen. Die bessere Vorhersagbarkeit für längere Vorläuferabstände lässt sich damit erklären, dass mehr Zeit für die Ausbildung von Resonanzstrukturen zur Verfügung steht. Diese Stromschwingungen wie in \figref{fig:streamer_current_sliece} mit einer dominanten Frequenz im dreistelligen MHz Bereich ca. \SI{100}{\mega\hertz} und einer niederfrequenten Modulation im zweistelligen MHz Bereich hier ca. \SI{10}{\mega\hertz} diese beiden Komponenten treffen beide Aussagen über die Länge der der Thermalisierungsphase des Kanals. Aus \tabref{tab:ds2-sample} lässt sich ablesen, dass die besonders wichtigen Frequenzen \(f_{34}\) & \(f_{24}\) für die meißten Werte einer niedrigen Frequen im mittleren zweistelligen MHz Bereich entsprechen, es ist anzumerken, dass mit der höheren Samplerate von \SI{2}{\giga\hertz} die zu Frequenzen im niedrigen dreistelligen Bereich werden. Somit könnte diese niederfrequente Modulation physikalisch besonders viel über die weitere Dynamik des Leitungskanals treffen. 

\subsubsection{Unterscheidung zwischen Entladungsregimen}
Der fundamentale Unterschied zwischen der Modelierbarkeit zwischen DS1 und DS2 bwz. zwischen Vorläufersignaturen, die weiter als \SI{1}{\micro\second}, und denen die weniger weit entfernt sind, deutet auf zwei phzsikalisch unterschiedlich Entladungsregime hin. 

In dem ersten Regime liegt ein direkter Durchschlag vor. Der Übergang von der Vorläufersignatur zur Hauptentladung erfolgt nahezu kontinuierlich. Die Features können somit den Vorläuferabstand nicht vorhersagen \(R^2 < 0\), da keine klar separierte Thermalisierungsphase existiert. Dies tritt also für die Vorläuferabstände die kleiner als \SI{1}{\micro\second} auf. 

In dem zweiten Regime bildet sich ein Streamerkanal mit moderater leitfähigkeit, der über einen messbaren Zeitraum existiert und charakteristische Oszillationen zeigt. Dieser Kanal muss vor der Hauptentladung thermalisiert werden. Die Vorhersagbarkeit von \(R^2 = 0,55\) für den DS2 zeigt, dass die Dynamik der Kanalthermalisierung in den Vorläufersignaturen kodiert ist.

\subsubsection{Frequenzabhängigkeit und Plasmadiagnositk}
Die Relevantz der Fourier-Koeffizienten die den Frequenzen im \SIrange{50}{430}{\mega\hertz} (vgl. \tabref{tab:ds2-features}, \tabref{tab:ds2-sample}) Bereich entsprechen unterstützt die H2 - Hypothese und bietet einen Einblick in die Plasmaparameter. Die Plasmafrequenz \(\omega_p = \sqrt{\frac{n_e e^2}{\epsilon_0 m_3}}\) mit Elektronendichten von ca.  \SIrange{1e19}{1e21}{\per\cubic\metre} entspricht Frequenzen von \SIrange{10}{300}{\giga\hertz}. Somit entsprechen die beobachteten relevanten Frequenzen nicht der Plasmafrequenz. Die beobachteten Frequenzen könnten auf geometrische Resonanzen des sich entwickelden Kanals entsprechen, sie könnten Raumladungsoszillationen aufgrund von Raumladungsinhomogenitäten ensprechen oder es könnten auch RC-Schwingkreis Effekten entsprechen. 

Es wurde beobachtet, dass eine höhere Abtastrate auch zu höheren Frequenz führt, somit könnten bei einer genügenden Auflösung auch potentiell Frequenzen im GHz Bereich auftauchen die relevant sind. 

\subsubsection{Eventlänge Vorhersage}
Die erheblich bessere Modellierbarkeit der Eventlänge für die DS3 udn DS4 \(R^2 = 0,73-0,76\) im Vergleich zu den den DS1 und DS2 mit \(R^2 = 0,17-0,37\) ist physikalisch aufschlussreich.
Die DS3 und 4 erhalten Features des unmittelbaren Eventstart die nur einige \SI{10}{\nano\second} vor dem Event liegen. In diesen Features ist die initiale Entladungsdynamik kodiert. Die Steigung des Stromanstieges, kann z.B. Aufschluss darüber geben, ob das Event länger oder kürzer dauert. Ein schneller Stromanstieg enspricht einer hohen initialen Amplitude des Stroms und führt so zu einer starken Dämpfung und somit zu einer schnelleren Energiedissipation und so zu einem kürzeren Event. Dahingen entspricht ein moderater Anstieg mit niedriger Amplitude einer langsameren Entladung die länger dauert. Die Relevanten Features der DS3 und 4 (vgl. \tabref{tab:ds3-features}, \tabref{tab:ds4-features}) sind direkte Maße der initialen Dynamik (Quantile, Grundpegel, Signalenergie etc.). Im Gegensatz kodieren die Featurs der Vorläufersignatur des DS1 und 2 den Zustand des Vorläuferkanals, dieser korreliert mit der nachfolgenden Hauptentladung. Es liegt jedoch kein deterministischer Zusammenhang zwischen dieser Signatur und den Eigenschaften des Events vor. Die verbleibende Varianz die nicht modeliert werden kann, lässt sich durch stochastiche Prozesse bei der Kanalentwicklung erklären. 

Es liegen somit zwei Phasen der Entladung vor. Eine stochastische Vorläuferphase (DS1 und 2), die Stromsignatur zeichnet sich in dieser durch Unregelmäßige, impulsartige Verläufe aus. Die Relevanten Features bilden diese Eigenschaften ab. Es liegen konkurrierende Elektronenlawinen, zufällige Raumladungsverteilungen und stochastische Ionisationsprozesse vor, die Vorhersagbarkeit der Eventlänge ist somit begrenzt.
Die zweite Phase ist eine deterministische Entladungsphase (DS3 und 4), diese Phase beginnt mit dem Eventstart und beinhält noch Regionen vor diesem, die direkt in diesen übergehen. Die Relevanten Features sind hier welche die die Basisverteilung, die Energie und die Variabilität beschreiben. Es dominieren deterministische elektrodznamische Prozesse, somit ist die Eventlänge hochgradig vorhersagbar. 
Diese beiden Phasen müssen nicht zusammen auftreten, die erste Phase im Kontext der DS1 und 2 tritt nur für einen kleinen Teil der aufgenommen Entladungen auf. 

